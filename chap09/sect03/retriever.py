
import os 
from dotenv import load_dotenv

load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")

# 임베딩 모델 선언하기
from langchain_openai import OpenAIEmbeddings

embedding = OpenAIEmbeddings(model="text-embedding-3-large", api_key=api_key)

# 언어 모델 불러오기 
from langchain_openai import ChatOpenAI
llm = ChatOpenAI(model="gpt-4o")

# load chroma store
from langchain_chroma import Chroma
print('Loading existing Chroma store')
persist_directory = 'D:\projects\gpt_agent_2025_book\chap09\chroma_store'

vectorStore = Chroma(
    persist_directory=persist_directory,
    embedding_function=embedding
)

# 리트리버 생성 
retriever = vectorStore.as_retriever(k=3)

# document chain 생성 
from langchain_classic.chains.combine_documents import create_stuff_documents_chain
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.output_parsers import StrOutputParser

question_answering_prompt = ChatPromptTemplate.from_messages(
    [
        (
            'system',
            "사용자의 질문에 대해 아래 context에 기반하여 답변하라. :\n\n{context}"
        ),
        MessagesPlaceholder(variable_name="messages")
    ]
)

document_chain = create_stuff_documents_chain(llm, question_answering_prompt) | StrOutputParser()

# query argumentation chain
query_argumentation_prompt = ChatPromptTemplate.from_messages(
    [
        MessagesPlaceholder(variable_name="messages"),
        (
            'system',
            "기존의 대화 내용을 활용하여 사용자가 질문한 의도를 파악해서 한 문자의 명료한 질무으로 반환하라. 대명사나 이, 저, 그와 같은 표현을 명확한 명사로 표현하라. :\n\n{query}"
        )
    ]
)

query_argumentation_chain = query_argumentation_prompt | llm | StrOutputParser()
